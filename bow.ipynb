{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c9ca8a-8d82-47d9-8b74-45a9de5dd36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05faaa-477c-4306-a887-991340d8106b",
   "metadata": {},
   "source": [
    "## Bag-of-Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec6a69-dcfe-43cf-8430-3784dc06ad58",
   "metadata": {},
   "source": [
    "Creating the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485fec7f-fd43-49d7-b530-0afa03571088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset.xlsx')\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for text in df['Abstract']:\n",
    "    if type(text) == str:\n",
    "        corpus.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851887cf-1b14-42b6-a0e6-d0234a5128eb",
   "metadata": {},
   "source": [
    "Creating the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea49e167-0183-43df-904a-93b9dda243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = sp.load('en_core_web_sm')\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "  return [t.text for t in nlp(doc) if not t.is_punct]\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, token_pattern=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c1dba-2f31-4fda-a66f-092e7a70eaac",
   "metadata": {},
   "source": [
    "Creating the BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c7d532-8e94-4dc3-9bfc-2d634565ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb4a95-b085-494f-a8ed-d6c0aa155bff",
   "metadata": {},
   "source": [
    "Calculating the cossine similarity between the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff92a17-0578-4764-9068-27c663f8d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cossine_sim = cosine_similarity(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910e9e0-cd33-4ad6-84f3-ce9898b2a746",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7075f-d404-4d8d-81c9-6289efbb381a",
   "metadata": {},
   "source": [
    "Creating vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e71991f-0b91-4f44-a1ec-451bc8e40575",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_pipes = [\"ner\", \"parser\"]\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "  with nlp.disable_pipes(*unwanted_pipes):\n",
    "    return [t.lemma_ for t in nlp(doc) if \\\n",
    "            not t.is_punct and \\\n",
    "            not t.is_space and \\\n",
    "            t.is_alpha]\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, token_pattern=None)\n",
    "features = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb5e1d-269c-44cf-9f11-20cd647a479b",
   "metadata": {},
   "source": [
    "Searching queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066c0532-5ce8-4f30-bf95-811fbea072f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(arr, k):\n",
    "  kth_largest = (k + 1) * -1\n",
    "  return np.argsort(arr)[:kth_largest:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472c0c31-c0fb-48ea-9451-c0d1ae6459f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Between 1960 and 1982, the National Cancer Institute (NCI) screened over 180,000 microbial-derived, some 16,000 marine organism-derived, and over 114,000 plant-derived extracts. A number of clinically effective chemotherapeutic agents were developed, mainly through collaborative efforts with the public and private sectors. These agents include paclitaxel, camptothecin derivatives, various anthracyclines, bleomycin, actinomycin and mitomycin. Since 1986, collections of plants and marine invertebrates have been performed in over 25 tropical and subtropical countries worldwide through contracts with botanical and marine biological organizations, working in close collaboration with source country organizations and subject to agreements with the source country authorities. Over 120,000 extracts are stored at low temperatures in the NCI Natural Products Repository and are made available to the scientific community for testing in screens related to all human diseases, subject to the signing of Material Transfer Agreements, which protects the rights of all parties, particularly those of the source countries. In addition, Memoranda of Understanding (MOU) have been signed with qualified organizations in over ten source countries for direct collaboration in the drug discovery and development process. A major goal of these collaborations is to promote drug discovery in the source country, with NCI collaborating in the preclinical and clinical development stages.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"biopiracy countries species\"]\n",
    "query_tfidf = vectorizer.transform(query)\n",
    "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()\n",
    "\n",
    "top_related_indices = top_k(cosine_similarities, 5)\n",
    "\n",
    "corpus[top_related_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8aaa37e-4026-48d4-bafe-0a333659f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The development of our society has been based on the use of biodiversity, especially for medicines and nutrition. Brazil is the nation with the largest biodiversity in the world accounting for more than 15% of all living species. The devastation of biodiversity in Brazil is critical and may not only cause the loss of species and genes that encode enzymes involved in the complex metabolism of organisms, but also the loss of a rich chemical diversity, which is a potential source for bioeconomy based on natural products and new synthetic derivatives. Bioeconomy focus on the use of bio-based products, instead of fossil-based ones and could address some of the important challenges faced by society. Considering the chemical and biological diversity of Brazil, this review highlights the Brazilian natural products that were successfully used to develop new products and the value of secondary metabolites from Brazilian biodiversity with potential application for new products and technologies. Additionally, we would like to address the importance of new technologies and scientific programs to support preservation policies, bioeconomy and strategies for the sustainable use of biodiversity.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"Brazil drugs\"]\n",
    "query_tfidf = vectorizer.transform(query)\n",
    "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()\n",
    "\n",
    "top_related_indices = top_k(cosine_similarities, 5)\n",
    "\n",
    "corpus[top_related_indices[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
